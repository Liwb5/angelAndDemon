{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liwb/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/liwb/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation, metrics   #Additional     scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112405, 875) (112405,) (28101, 875)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/liwb/Documents/projects/angelAndDemon/')\n",
    "version='4'\n",
    "trainPath = './dataAfterProcess/trainRes%s.csv'%(version)\n",
    "trainData = pd.read_csv(trainPath, header=None)\n",
    "X = trainData.values[:,0:trainData.shape[1]-1]\n",
    "y = trainData.values[:,trainData.shape[1]-1]\n",
    "\n",
    "testPath = './dataAfterProcess/testRes%s.csv'%(version)\n",
    "testData = pd.read_csv(testPath, header=None)\n",
    "testX = testData.values\n",
    "print(X.shape, y.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112405, 1137)\n",
      "330.0\n",
      "(28101, 1136)\n"
     ]
    }
   ],
   "source": [
    "#淼鑫的数据\n",
    "import pickle\n",
    "f = open('./dataAfterProcess/train_set.js','rb')\n",
    "train_set = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "train_set = np.array(train_set)\n",
    "\n",
    "f = open('./dataAfterProcess/valid_set.js','rb')\n",
    "valid_set = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "valid_set = np.array(valid_set)\n",
    "\n",
    "train_mx = np.vstack((train_set, valid_set))\n",
    "print(train_mx.shape)\n",
    "print(sum(train_mx[:,train_mx.shape[1]-1]))\n",
    "\n",
    "X_mx = train_mx[:,0:train_mx.shape[1]-1]\n",
    "y_mx = train_mx[:,train_mx.shape[1]-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = open('./dataAfterProcess/test_set.js','rb')\n",
    "test_set = pickle.load(f)\n",
    "f.close()\n",
    "testX_mx = np.array(test_set)\n",
    "print(testX_mx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost 的交叉验证，一般xgb的交叉验证是用来观测那些参数的效果好。然后再用好的参数去train。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对xgboost模型进行交叉验证，并且画出ROC曲线。\n",
    "def xgboost_cv(X, y, xgboost, Kfold):\n",
    "    random_state = np.random.RandomState(0)\n",
    "    skf = StratifiedKFold(n_splits=Kfold,random_state=random_state) #k fold交叉验证\n",
    "    i=0\n",
    "    xgb_models = []\n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "        xgb_model = xgboost\n",
    "        xgb_model = xgb_model.fit(X[train_index], y[train_index], \n",
    "                                  eval_set=[(X[train_index], y[train_index]),\n",
    "                                            (X[test_index], y[test_index])],\n",
    "                                  eval_metric = \"auc\",\n",
    "                                  verbose = False)\n",
    "\n",
    "        #evals_result = xgb_model.evals_result()\n",
    "        #print(evals_result)\n",
    "        probas_ = xgb_model.predict_proba(X[test_index])\n",
    "\n",
    "        #[:,1]二分类有0的概率，也有预测为1的概率，这里提取预测为1的概率\n",
    "        fpr, tpr, thresholds = roc_curve(y[test_index], probas_[:,1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        score = roc_auc_score(y[test_index] , probas_[:,1])#验证集的auc分数\n",
    "\n",
    "        train_probas = xgb_model.predict_proba(X[train_index])\n",
    "        train_score = roc_auc_score(y[train_index], train_probas[:,1])#训练集的auc分数\n",
    "        print(\"auc_test: %5f,auc_train:%5f in %d fold. index shape:%d\"\\\n",
    "              %(score, train_score, i, len(train_index))) \n",
    "\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.8,\n",
    "                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        i += 1\n",
    "        xgb_models.append(xgb_model)\n",
    "    \n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Luck', alpha=.8)\n",
    "\n",
    "    plt.show()\n",
    "    return xgb_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_test: 0.897116,auc_train:1.000000 in 0 fold. index shape:89924\n",
      "auc_test: 0.916728,auc_train:1.000000 in 1 fold. index shape:89924\n",
      "auc_test: 0.902492,auc_train:1.000000 in 2 fold. index shape:89924\n",
      "auc_test: 0.900794,auc_train:1.000000 in 3 fold. index shape:89924\n",
      "auc_test: 0.884229,auc_train:1.000000 in 4 fold. index shape:89924\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3BV/HQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00e5263160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_model_cv = xgb.XGBClassifier(booster='gbtree',\n",
    "                              silent=True,\n",
    "                              #n_jobs=5, #不设置的话，自动获得最大线程数\n",
    "                              #以上为general params\n",
    "                              \n",
    "                              learning_rate = 0.1,#在xgboost的package中等价于eta参数\n",
    "                              min_child_weight = 2, #控制过拟合，越大越不会过拟合\n",
    "                              \n",
    "                              max_depth=100, #控制过拟合，越小越不会过拟合\n",
    "                              max_delta_step = 1, #数据不均衡的时候可以用\n",
    "                              gamma = 0,         #模型在默认情况下，对于一个节点的划分\n",
    "                                                 #只有在其loss function 得到结果大于0的情况下才进行，\n",
    "                                                 #而gamma 给定了所需的最低loss function的值.\n",
    "                                                 #所以gamma越大越保守（conservation）\n",
    "                              subsample = 0.8,    #太大会过拟合，太小会欠拟合\n",
    "                              colsample_bytree=0.8, #\n",
    "                              reg_lambda = 100, #L2正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              reg_alpha = 0, #L1正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              scale_pos_weight=340,\n",
    "                              #以上是booster的参数\n",
    "                              \n",
    "                              \n",
    "                              random_state = 0,\n",
    "                              n_estimators = 200)#树的棵树\n",
    "\n",
    "\n",
    "xgbModels = xgboost_cv(X, y, xgb_model_cv, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对交叉验证得到的模型，将它们用于测试集，并将平均得到的结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib #jbolib模块\n",
    "#将xgboost交叉验证的几个模型去预测测试集，并且对其取平均\n",
    "def testModel(models, testX, versionSaved='100'):\n",
    "    i=0\n",
    "    probas = []\n",
    "    for xgb_final in models:\n",
    "        predict = xgb_final.predict(testX)\n",
    "        #查看有多少样本被预测为1\n",
    "        print('samples have been predicted as positive samples: ', \\\n",
    "              sum(predict),'in %d model'%(i))\n",
    "        probas_ = xgb_final.predict_proba(testX)\n",
    "        probas.append(probas_[:,1])\n",
    "        i+=1\n",
    "\n",
    "    print(type(probas))\n",
    "    print(len(probas), len(probas[0]))\n",
    "    predict = np.sum(probas, axis=0)/len(probas)\n",
    "    #保存测试集的预测结果\n",
    "    result = pd.read_csv('./originalDataset/exampleSubmission.csv')\n",
    "    result.label = predict\n",
    "    result.to_csv('./outputs/submission%s.csv'%(versionSaved), index=False)\n",
    "    \n",
    "    #joblib.dump(xgb_final, './models/xgbModel_%s.model'%(versionSaved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874']\ntraining data did not have the following fields: f599, f396, f474, f788, f383, f203, f744, f357, f251, f208, f739, f830, f604, f404, f457, f537, f650, f790, f513, f220, f377, f676, f848, f268, f493, f371, f318, f441, f381, f480, f244, f527, f284, f279, f385, f704, f168, f431, f321, f714, f173, f442, f627, f271, f545, f308, f610, f314, f196, f820, f815, f557, f706, f467, f446, f312, f850, f752, f153, f656, f436, f747, f172, f164, f833, f776, f634, f520, f405, f390, f645, f753, f563, f490, f485, f288, f609, f771, f798, f618, f647, f866, f695, f238, f456, f813, f817, f740, f195, f703, f745, f249, f177, f255, f302, f725, f199, f240, f510, f666, f234, f236, f591, f187, f795, f834, f503, f421, f843, f709, f150, f333, f317, f352, f746, f202, f533, f707, f328, f737, f486, f829, f816, f261, f281, f235, f764, f398, f407, f657, f605, f188, f861, f554, f601, f653, f304, f570, f497, f433, f269, f325, f568, f665, f430, f579, f587, f690, f607, f451, f411, f237, f169, f276, f499, f285, f330, f362, f369, f760, f823, f826, f160, f724, f654, f534, f459, f414, f683, f438, f287, f874, f697, f730, f784, f519, f869, f468, f491, f589, f386, f827, f322, f667, f374, f792, f722, f822, f418, f152, f399, f477, f345, f621, f323, f832, f853, f254, f370, f623, f791, f415, f870, f245, f257, f409, f482, f720, f594, f576, f300, f726, f797, f207, f313, f800, f439, f223, f831, f299, f810, f498, f765, f651, f239, f721, f403, f511, f259, f643, f523, f644, f819, f229, f807, f337, f713, f410, f593, f748, f293, f639, f521, f394, f228, f339, f171, f267, f243, f872, f422, f380, f757, f551, f783, f219, f546, f566, f673, f649, f775, f423, f620, f659, f759, f327, f526, f715, f332, f640, f280, f613, f808, f868, f571, f572, f575, f638, f462, f774, f361, f671, f799, f578, f402, f710, f505, f793, f818, f258, f213, f373, f201, f558, f590, f161, f200, f574, f606, f506, f334, f387, f227, f464, f450, f193, f628, f509, f163, f741, f824, f567, f846, f750, f608, f233, f805, f693, f427, f461, f857, f742, f751, f248, f532, f286, f368, f560, f700, f413, f777, f524, f489, f272, f858, f155, f166, f273, f283, f343, f738, f230, f347, f763, f863, f842, f384, f541, f192, f274, f452, f206, f372, f531, f655, f680, f762, f767, f641, f768, f167, f719, f844, f226, f158, f264, f290, f684, f779, f211, f787, f512, f495, f253, f295, f186, f809, f151, f191, f307, f625, f670, f556, f522, f338, f851, f736, f756, f803, f550, f342, f247, f326, f565, f408, f836, f766, f547, f549, f615, f504, f663, f354, f838, f429, f440, f426, f837, f660, f603, f632, f205, f664, f755, f246, f222, f681, f781, f581, f159, f555, f539, f543, f364, f501, f367, f225, f692, f315, f218, f661, f802, f642, f770, f617, f419, f463, f542, f569, f185, f319, f382, f483, f500, f624, f270, f252, f379, f806, f841, f701, f465, f801, f691, f782, f631, f622, f772, f585, f432, f518, f190, f366, f311, f672, f675, f375, f359, f282, f530, f198, f708, f278, f735, f514, f794, f400, f397, f355, f174, f696, f864, f743, f811, f702, f178, f303, f552, f391, f320, f215, f840, f305, f785, f658, f536, f346, f351, f758, f242, f445, f435, f561, f182, f296, f749, f289, f559, f475, f487, f291, f825, f224, f453, f183, f619, f417, f476, f716, f614, f867, f294, f471, f157, f630, f204, f611, f508, f306, f689, f194, f873, f595, f712, f582, f688, f629, f773, f156, f292, f335, f458, f447, f162, f231, f454, f525, f698, f845, f348, f682, f184, f181, f341, f434, f584, f731, f528, f401, f470, f646, f648, f210, f780, f544, f209, f839, f732, f694, f849, f761, f812, f679, f507, f389, f496, f277, f221, f449, f535, f728, f492, f852, f425, f669, f592, f358, f256, f360, f515, f598, f678, f562, f633, f860, f455, f420, f232, f406, f705, f821, f538, f265, f600, f553, f734, f612, f460, f262, f329, f733, f154, f472, f149, f855, f859, f298, f686, f473, f588, f395, f336, f856, f484, f786, f469, f769, f393, f835, f729, f363, f871, f392, f344, f214, f443, f378, f616, f189, f517, f636, f175, f217, f176, f814, f212, f586, f583, f828, f577, f494, f297, f718, f685, f865, f573, f754, f540, f626, f331, f388, f727, f548, f580, f711, f789, f180, f674, f637, f428, f448, f412, f263, f416, f778, f862, f350, f275, f516, f301, f310, f424, f488, f596, f804, f602, f179, f266, f309, f353, f662, f349, f479, f170, f365, f597, f717, f652, f677, f529, f340, f250, f502, f376, f444, f197, f356, f847, f796, f241, f466, f216, f564, f165, f854, f687, f668, f260, f316, f699, f481, f478, f324, f635, f723, f437",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-22c5c7982b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'875ensemble'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-786269a4e167>\u001b[0m in \u001b[0;36mtestModel\u001b[0;34m(models, versionSaved)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxgb_final\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#查看有多少样本被预测为1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'samples have been predicted as positive samples: '\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'in %d model'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    525\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[1;32m    526\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                                                  ntree_limit=ntree_limit)\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mcolumn_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0moption_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;36m0x08\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1286\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874']\ntraining data did not have the following fields: f599, f396, f474, f788, f383, f203, f744, f357, f251, f208, f739, f830, f604, f404, f457, f537, f650, f790, f513, f220, f377, f676, f848, f268, f493, f371, f318, f441, f381, f480, f244, f527, f284, f279, f385, f704, f168, f431, f321, f714, f173, f442, f627, f271, f545, f308, f610, f314, f196, f820, f815, f557, f706, f467, f446, f312, f850, f752, f153, f656, f436, f747, f172, f164, f833, f776, f634, f520, f405, f390, f645, f753, f563, f490, f485, f288, f609, f771, f798, f618, f647, f866, f695, f238, f456, f813, f817, f740, f195, f703, f745, f249, f177, f255, f302, f725, f199, f240, f510, f666, f234, f236, f591, f187, f795, f834, f503, f421, f843, f709, f150, f333, f317, f352, f746, f202, f533, f707, f328, f737, f486, f829, f816, f261, f281, f235, f764, f398, f407, f657, f605, f188, f861, f554, f601, f653, f304, f570, f497, f433, f269, f325, f568, f665, f430, f579, f587, f690, f607, f451, f411, f237, f169, f276, f499, f285, f330, f362, f369, f760, f823, f826, f160, f724, f654, f534, f459, f414, f683, f438, f287, f874, f697, f730, f784, f519, f869, f468, f491, f589, f386, f827, f322, f667, f374, f792, f722, f822, f418, f152, f399, f477, f345, f621, f323, f832, f853, f254, f370, f623, f791, f415, f870, f245, f257, f409, f482, f720, f594, f576, f300, f726, f797, f207, f313, f800, f439, f223, f831, f299, f810, f498, f765, f651, f239, f721, f403, f511, f259, f643, f523, f644, f819, f229, f807, f337, f713, f410, f593, f748, f293, f639, f521, f394, f228, f339, f171, f267, f243, f872, f422, f380, f757, f551, f783, f219, f546, f566, f673, f649, f775, f423, f620, f659, f759, f327, f526, f715, f332, f640, f280, f613, f808, f868, f571, f572, f575, f638, f462, f774, f361, f671, f799, f578, f402, f710, f505, f793, f818, f258, f213, f373, f201, f558, f590, f161, f200, f574, f606, f506, f334, f387, f227, f464, f450, f193, f628, f509, f163, f741, f824, f567, f846, f750, f608, f233, f805, f693, f427, f461, f857, f742, f751, f248, f532, f286, f368, f560, f700, f413, f777, f524, f489, f272, f858, f155, f166, f273, f283, f343, f738, f230, f347, f763, f863, f842, f384, f541, f192, f274, f452, f206, f372, f531, f655, f680, f762, f767, f641, f768, f167, f719, f844, f226, f158, f264, f290, f684, f779, f211, f787, f512, f495, f253, f295, f186, f809, f151, f191, f307, f625, f670, f556, f522, f338, f851, f736, f756, f803, f550, f342, f247, f326, f565, f408, f836, f766, f547, f549, f615, f504, f663, f354, f838, f429, f440, f426, f837, f660, f603, f632, f205, f664, f755, f246, f222, f681, f781, f581, f159, f555, f539, f543, f364, f501, f367, f225, f692, f315, f218, f661, f802, f642, f770, f617, f419, f463, f542, f569, f185, f319, f382, f483, f500, f624, f270, f252, f379, f806, f841, f701, f465, f801, f691, f782, f631, f622, f772, f585, f432, f518, f190, f366, f311, f672, f675, f375, f359, f282, f530, f198, f708, f278, f735, f514, f794, f400, f397, f355, f174, f696, f864, f743, f811, f702, f178, f303, f552, f391, f320, f215, f840, f305, f785, f658, f536, f346, f351, f758, f242, f445, f435, f561, f182, f296, f749, f289, f559, f475, f487, f291, f825, f224, f453, f183, f619, f417, f476, f716, f614, f867, f294, f471, f157, f630, f204, f611, f508, f306, f689, f194, f873, f595, f712, f582, f688, f629, f773, f156, f292, f335, f458, f447, f162, f231, f454, f525, f698, f845, f348, f682, f184, f181, f341, f434, f584, f731, f528, f401, f470, f646, f648, f210, f780, f544, f209, f839, f732, f694, f849, f761, f812, f679, f507, f389, f496, f277, f221, f449, f535, f728, f492, f852, f425, f669, f592, f358, f256, f360, f515, f598, f678, f562, f633, f860, f455, f420, f232, f406, f705, f821, f538, f265, f600, f553, f734, f612, f460, f262, f329, f733, f154, f472, f149, f855, f859, f298, f686, f473, f588, f395, f336, f856, f484, f786, f469, f769, f393, f835, f729, f363, f871, f392, f344, f214, f443, f378, f616, f189, f517, f636, f175, f217, f176, f814, f212, f586, f583, f828, f577, f494, f297, f718, f685, f865, f573, f754, f540, f626, f331, f388, f727, f548, f580, f711, f789, f180, f674, f637, f428, f448, f412, f263, f416, f778, f862, f350, f275, f516, f301, f310, f424, f488, f596, f804, f602, f179, f266, f309, f353, f662, f349, f479, f170, f365, f597, f717, f652, f677, f529, f340, f250, f502, f376, f444, f197, f356, f847, f796, f241, f466, f216, f564, f165, f854, f687, f668, f260, f316, f699, f481, f478, f324, f635, f723, f437"
     ]
    }
   ],
   "source": [
    "testModel([clf2], testX, '875ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "### 训练模型，并且使用测试集预测。将结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib #jbolib模块\n",
    "\n",
    "#训练模型，并且用测试集测试，得到预测结果，保存预测结果\n",
    "def xgboostTrain(X, y, testX, xgb_final, versionSaved='100', params=None):\n",
    "    xgb_final = xgb_final.fit(X, y, \n",
    "                     eval_set=[(X, y)],\n",
    "                     eval_metric = \"auc\",\n",
    "                     verbose = False)\n",
    "    \n",
    "    print(xgb_final.evals_result())\n",
    "    predict = xgb_final.predict(testX)\n",
    "    #查看有多少样本被预测为1\n",
    "    print(sum(predict),' samples have been predicted as positive samples')\n",
    "    probas_ = xgb_final.predict_proba(testX)\n",
    "    probas = probas_[:,1]\n",
    "    \n",
    "    #保存测试集的预测结果\n",
    "    result = pd.read_csv('./originalDataset/exampleSubmission.csv')\n",
    "    result.label = probas\n",
    "    result.to_csv('./outputs/submission%s.csv'%(versionSaved), index=False)\n",
    "    \n",
    "    #保存模型\n",
    "    joblib.dump(xgb_final, './models/xgbModel_%s.model'%(versionSaved))\n",
    "    #clf2 = joblib.load('./models/xgb_0501test2.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'validation_0': {'auc': [0.930371, 0.98661, 0.992024, 0.994209, 0.996645, 0.996554, 0.997383, 0.998314, 0.998789, 0.999085, 0.999282, 0.999357, 0.99947, 0.999582, 0.999644, 0.999699, 0.999742, 0.999765, 0.999774, 0.999782, 0.999783, 0.999802, 0.999808, 0.999819, 0.99982, 0.999826, 0.99984, 0.999848, 0.999861, 0.999862, 0.999866, 0.999872, 0.999878, 0.999891, 0.999893, 0.999893, 0.999905, 0.99991, 0.999913, 0.999917, 0.999922, 0.999926, 0.999931, 0.999937, 0.999941, 0.999942, 0.999946, 0.999949, 0.999952, 0.999955, 0.999959, 0.999965, 0.999967, 0.99997, 0.999973, 0.999975, 0.999978, 0.99998, 0.99998, 0.999982, 0.999983, 0.999983, 0.999986, 0.999986, 0.999988, 0.999988, 0.99999, 0.999991, 0.999992, 0.999993, 0.999993, 0.999993, 0.999994, 0.999993, 0.999993, 0.999994, 0.999994, 0.999994, 0.999995, 0.999995, 0.999995, 0.999995, 0.999995, 0.999996, 0.999996, 0.999997, 0.999997, 0.999997, 0.999997, 0.999997, 0.999997, 0.999997, 0.999997, 0.999998, 0.999998, 0.999998, 0.999998, 0.999998, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 0.999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}\n",
      "57.0  samples have been predicted as positive samples\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./originalDataset/exampleSubmission.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5b890b0c1633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#xgboostTrain(X, y, testX, xgb_final, versionSaved= '200depth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mxgboostTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX_mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversionSaved\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'0501_mx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-50aaed249bf1>\u001b[0m in \u001b[0;36mxgboostTrain\u001b[0;34m(X, y, testX, xgb_final, versionSaved, params)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#保存测试集的预测结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./originalDataset/exampleSubmission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./outputs/submission%s.csv'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversionSaved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/liwb/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./originalDataset/exampleSubmission.csv' does not exist"
     ]
    }
   ],
   "source": [
    "xgb_final = xgb.XGBClassifier(booster='gbtree',\n",
    "                              silent=True,\n",
    "                              #n_jobs=5, #不设置的话，自动获得最大线程数\n",
    "                              #以上为general params\n",
    "                              \n",
    "                              learning_rate = 0.1,#在xgboost的package中等价于eta参数\n",
    "                              min_child_weight = 2, #控制过拟合，越大越不会过拟合\n",
    "                              \n",
    "                              max_depth=100, #控制过拟合，越小越不会过拟合\n",
    "                              max_delta_step = 1, #数据不均衡的时候可以用\n",
    "                              gamma = 0,         #模型在默认情况下，对于一个节点的划分\n",
    "                                                 #只有在其loss function 得到结果大于0的情况下才进行，\n",
    "                                                 #而gamma 给定了所需的最低loss function的值.\n",
    "                                                 #所以gamma越大越保守（conservation）\n",
    "                              subsample = 0.8,    #太大会过拟合，太小会欠拟合\n",
    "                              colsample_bytree=0.8, #\n",
    "                              reg_lambda = 100, #L2正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              reg_alpha = 0, #L1正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              scale_pos_weight=340,\n",
    "                              #以上是booster的参数\n",
    "                              \n",
    "                              \n",
    "                              random_state = 0,\n",
    "                              n_estimators = 200)#树的棵树\n",
    "\n",
    "#xgboostTrain(X, y, testX, xgb_final, versionSaved= '200depth')\n",
    "xgboostTrain(X_mx, y_mx, testX_mx, xgb_final, versionSaved= '0501_mx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 用gridsearch进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112405, 1136) (112405,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1}\n",
      "0.8847955576284819\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    #'n_estimators':[i for i in range(30,50,2)],\n",
    "    #'max_depth':[i for i in range(3,10)],\n",
    "    #'min_child_weight':[i for i in range(1,6)],\n",
    "    #'gamma':[i/10.0 for i in range(5)],\n",
    "    #'subsample':[i/10.0 for i in range(5,10)],\n",
    "    #'colsample_bytree':[i/10.0 for i in range(5,10)],\n",
    "    #'reg_lambda':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    #'max_delta_step':[i for i in range(1,10)],\n",
    "    'learning_rate':[0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(booster='gbtree',\n",
    "                              silent=True,\n",
    "                              #n_jobs=5, #不设置的话，自动获得最大线程数\n",
    "                              #以上为general params\n",
    "                              \n",
    "                              learning_rate = 0.1,#在xgboost的package中等价于eta参数\n",
    "                              min_child_weight = 2, #控制过拟合，越大越不会过拟合\n",
    "                              \n",
    "                              max_depth=9, #控制过拟合，越小越不会过拟合\n",
    "                              max_delta_step = 1, #数据不均衡的时候可以用\n",
    "                              gamma = 0,         #模型在默认情况下，对于一个节点的划分\n",
    "                                                 #只有在其loss function 得到结果大于0的情况下才进行，\n",
    "                                                 #而gamma 给定了所需的最低loss function的值.\n",
    "                                                 #所以gamma越大越保守（conservation）\n",
    "                              subsample = 0.8,    #太大会过拟合，太小会欠拟合\n",
    "                              colsample_bytree=0.8, #\n",
    "                              reg_lambda = 100, #L2正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              reg_alpha = 0, #L1正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              scale_pos_weight=340,\n",
    "                              #以上是booster的参数\n",
    "                              \n",
    "                              \n",
    "                              random_state = 0,\n",
    "                              n_estimators = 48)#树的棵树\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator=xgb_model, \n",
    "                        param_grid = param_test1, \n",
    "                        scoring = \"roc_auc\",\n",
    "                        n_jobs = 4,\n",
    "                        iid = False, \n",
    "                        cv = 5)\n",
    "\n",
    "\n",
    "gsearch1.fit(X, y)\n",
    "print(gsearch1.best_params_)\n",
    "#print(gsearch1.best_estimator_)\n",
    "print(gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': 2, 'max_depth': 9}\n",
      "0.8760356633477311\n"
     ]
    }
   ],
   "source": [
    "#print(gsearch1.cv_results_)\n",
    "print(gsearch1.best_params_)\n",
    "#print(gsearch1.best_estimator_)\n",
    "print(gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation, metrics   #Additional     scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "        \n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)\n",
    "    \n",
    "    def feature_importances(self, x, y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0,\n",
    "    'class_weight':{0:1,1:340},\n",
    "    'random_state':0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0,\n",
    "    'random_state':0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75,\n",
    "    'random_state':0\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'subsample':0.8,\n",
    "    'verbose': 0,\n",
    "    'random_state':0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Create 5 objects that represent our 4 models\n",
    "SEED = 0\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf, X, y, testX, Kfold):\n",
    "    skf = StratifiedKFold(n_splits=Kfold,random_state=random_state) #k fold交叉验证\n",
    "    \n",
    "    oof_test_skf = np.empty((Kfold, testX.shape[0]))\n",
    "    oof_train = np.zeros((X.shape[0],))\n",
    "    oof_test = np.zeros((testX.shape[0],))\n",
    "    i=0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        clf.train(X[train_index], y[train_index])\n",
    "        oof_train[test_index] = clf.predict(X[test_index])\n",
    "        \n",
    "        oof_test_skf[i,:] = clf.predict(testX)\n",
    "        i += 1\n",
    "    \n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)#测试集需要求均值\n",
    "    \n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liwb/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py:304: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, X, y, testX,5) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,X, y, testX,5) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, X, y, testX,5) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,X, y, testX,5) # Gradient Boost\n",
    "svc_oof_train, svc_oof_test = get_oof(svc,X, y, testX,5) # Support Vector Classifier\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112405, 5) (28101, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.9, learning_rate=0.1,\n",
       "       max_delta_step=1, max_depth=5, min_child_weight=2, missing=None,\n",
       "       n_estimators=480, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=100, scale_pos_weight=340, seed=None, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(booster='gbtree',\n",
    "                              silent=True,\n",
    "                              #n_jobs=5, #不设置的话，自动获得最大线程数\n",
    "                              #以上为general params\n",
    "                              \n",
    "                              learning_rate = 0.1,#在xgboost的package中等价于eta参数\n",
    "                              min_child_weight = 2, #控制过拟合，越大越不会过拟合\n",
    "                              \n",
    "                              max_depth=5, #控制过拟合，越小越不会过拟合\n",
    "                              max_delta_step = 1, #数据不均衡的时候可以用\n",
    "                              gamma = 0.9,         #模型在默认情况下，对于一个节点的划分\n",
    "                                                 #只有在其loss function 得到结果大于0的情况下才进行，\n",
    "                                                 #而gamma 给定了所需的最低loss function的值.\n",
    "                                                 #所以gamma越大越保守（conservation）\n",
    "                              subsample = 0.8,    #太大会过拟合，太小会欠拟合\n",
    "                              colsample_bytree=0.8, #\n",
    "                              reg_lambda = 100, #L2正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              reg_alpha = 0, #L1正则化的权重参数,给linear模型用的。gbtree不用\n",
    "                              scale_pos_weight=340,\n",
    "                              #以上是booster的参数\n",
    "                             \n",
    "                              \n",
    "                              random_state = 0,\n",
    "                              n_estimators = 480)#树的棵树\n",
    "\n",
    "xgb_model.fit(x_train, y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
